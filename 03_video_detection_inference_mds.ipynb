{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eckr0jDiSYRz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnbhzREhhe8T"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-lightning==1.9.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf-XW4Z3QJQI"
      },
      "source": [
        "# Inference with torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MwTn8sdJzmT"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Avli8tydKH0j"
      },
      "outputs": [],
      "source": [
        "!pip3 install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSvU3qjEYHXy"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoGURKDJY0Iy"
      },
      "outputs": [],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIqu76lKKwv9"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2D4qP52iRKh"
      },
      "outputs": [],
      "source": [
        "class RetinaRehead(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = torchvision.models.detection.retinanet_resnet50_fpn_v2(weights='DEFAULT')\n",
        "        self.detector = torch.nn.Conv2d(256, 10, kernel_size=3, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        res = self.model.backbone.forward(input)\n",
        "        res = res['0']\n",
        "        res = self.detector.forward(res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lsmz0_EiVW5"
      },
      "outputs": [],
      "source": [
        "class PLModel(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model.forward(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXf9SdyaiY9y"
      },
      "outputs": [],
      "source": [
        "state = torch.load(\n",
        "    '/content/drive/MyDrive/course_to_middle_old/weights/detector_checkpoint.ckpt',\n",
        "    map_location='cpu')\n",
        "state = state['state_dict']\n",
        "\n",
        "model = PLModel(RetinaRehead())\n",
        "model.load_state_dict(state)\n",
        "\n",
        "## YOUR CODE HERE\n",
        "model = model.model.to(device).eval().half() # model = model.model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEeasohhM-Qq"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "_ = model.forward(torch.rand(1, 3, 512, 512).half().to(device))  #warm up # _ = model.forward(torch.rand(1, 3, 512, 512).to(device))  #warm up\n",
        "print(_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bAPhWjiRqPJ"
      },
      "outputs": [],
      "source": [
        "torch.rand(1, 3, 512, 512, dtype=torch.half).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQFKxYoJMPOF"
      },
      "outputs": [],
      "source": [
        "img = Image.open('/content/drive/MyDrive/course_to_middle_old/test_images_videos/photo1681218949.jpeg')\n",
        "shape = np.array(img.size)\n",
        "shape = (shape / shape[1] * 512).astype(int)\n",
        "shape = shape // 32 * 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEF7nqOuWgeb"
      },
      "outputs": [],
      "source": [
        "shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0rmEduDj-QN"
      },
      "outputs": [],
      "source": [
        "times_for_preproc = []\n",
        "\n",
        "for i in range(100):\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  t0 = time.time()\n",
        "\n",
        "  img = img.resize(size=shape)\n",
        "  t_img = (torch.tensor(np.array(img)).permute([2, 0, 1]).unsqueeze(0) / 255.0 - 0.5)/0.25\n",
        "  ## YOUR CODE HERE\n",
        "  t_img = t_img.half().to(device) # t_img = t_img.to(device)\n",
        "\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  times_for_preproc.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for preprocessing {np.mean(np.array(times_for_preproc))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOKgSJ-eMrLg"
      },
      "outputs": [],
      "source": [
        "t_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyXdcdKjMUsP"
      },
      "outputs": [],
      "source": [
        "times_for_inf_torch = []\n",
        "\n",
        "for i in range(100):\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  t0 = time.time()\n",
        "\n",
        "  ## YOUR CODE HERE\n",
        "  res = model.half().forward(t_img) # res = model.forward(t_img)\n",
        "\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  times_for_inf_torch.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for inference torch {np.mean(np.array(times_for_inf_torch))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7ENe1YemcRT"
      },
      "outputs": [],
      "source": [
        "def decode_result(datum, threshold=1.0, r=8, iou_threshold=0.7):\n",
        "    bboxes = {'boxes': [], 'scores': [], 'labels': []}\n",
        "    datum = {0: datum[:5, :, :], \n",
        "             1: datum[5:, :, :]}\n",
        "\n",
        "    for label in [0, 1]:\n",
        "        mask = (datum[label][0, :, :] >= threshold)\n",
        "\n",
        "        x_cell = torch.arange(mask.shape[1], device=datum[label].device)\n",
        "        y_cell = torch.arange(mask.shape[0], device=datum[label].device)\n",
        "\n",
        "        y_cell, x_cell = torch.meshgrid(y_cell, x_cell)\n",
        "\n",
        "        x_cell = x_cell[mask]\n",
        "        y_cell = y_cell[mask]\n",
        "        \n",
        "        x_shift = datum[label][2, :, :][mask]\n",
        "        y_shift = datum[label][1, :, :][mask]\n",
        "\n",
        "        x = (x_cell + x_shift) * r\n",
        "        y = (y_cell + y_shift) * r\n",
        "\n",
        "        w = datum[label][4, :, :][mask].exp() * r\n",
        "        h = datum[label][3, :, :][mask].exp() * r\n",
        "\n",
        "        scores = datum[label][0, :, :][mask]\n",
        "\n",
        "\n",
        "        for index in range(len(x)):\n",
        "            bboxes['boxes'].append([x[index] - w[index]/2, \n",
        "                         y[index] - h[index]/2, \n",
        "                         x[index] + w[index]/2, \n",
        "                         y[index] + h[index]/2])\n",
        "            bboxes['scores'].append(scores[index])\n",
        "            bboxes['labels'].append(label)\n",
        "\n",
        "    bboxes['boxes'] = torch.tensor(bboxes['boxes']).reshape([-1, 4])\n",
        "    bboxes['scores'] = torch.tensor(bboxes['scores'])\n",
        "    bboxes['labels'] = torch.tensor(bboxes['labels'])\n",
        "\n",
        "    to_keep = torchvision.ops.nms(bboxes['boxes'], bboxes['scores'], iou_threshold=iou_threshold)\n",
        "\n",
        "    bboxes['boxes'] = bboxes['boxes'][to_keep]\n",
        "    bboxes['scores'] = bboxes['scores'][to_keep]\n",
        "    bboxes['labels'] = bboxes['labels'][to_keep]\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "\n",
        "def decode_batch(batch, threshold=0.1, iou_threshold=0.3):\n",
        "    res = []\n",
        "    for index in range(batch.shape[0]):\n",
        "        res.append(decode_result(batch[index], \n",
        "                   threshold=threshold, \n",
        "                   iou_threshold=iou_threshold))\n",
        "    return res\n",
        "\n",
        "def draw_box(coords, label):\n",
        "    # print(coords)\n",
        "    # print(label)\n",
        "    # return None\n",
        "    x = np.array((coords[0], coords[2]))\n",
        "    y = np.array((coords[1], coords[3]))\n",
        "    color = 'g'\n",
        "    if label == 0:\n",
        "        color = 'r'\n",
        "\n",
        "    plt.plot(x.mean(), y.mean(), '*' + color)\n",
        "\n",
        "    plt.plot([x[0], x[0]], [y[0], y[1]], color)\n",
        "    plt.plot([x[1], x[1]], [y[0], y[1]], color)\n",
        "    plt.plot([x[0], x[1]], [y[0], y[0]], color)\n",
        "    plt.plot([x[0], x[1]], [y[1], y[1]], color)\n",
        "    # plt.text(x[0], y[0], label, backgroundcolor='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkjVpWyxMWr7"
      },
      "outputs": [],
      "source": [
        "clone_res = res.clone().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Y-9wzDN8yC"
      },
      "outputs": [],
      "source": [
        "times_for_postproc = []\n",
        "\n",
        "for i in range(100):\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  t0 = time.time()\n",
        "\n",
        "  ## YOUR CODE HERE\n",
        "  clone_res_cpu = clone_res # clone_res_cpu = clone_res.cpu()\n",
        "  ## YOUR CODE HERE\n",
        "  clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :].float()).half() # clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :])\n",
        "  ## YOUR CODE HERE\n",
        "  bboxes = decode_result(clone_res_cpu[0].float(), threshold=0.2, iou_threshold=0.2) # bboxes = decode_result(clone_res_gpu[0], threshold=0.2, iou_threshold=0.2)\n",
        "\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  times_for_postproc.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for postprocessing {np.mean(np.array(times_for_postproc))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owp8XIerr2Nu"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n",
        "for index in range(len(bboxes['boxes'])):\n",
        "    draw_box(bboxes['boxes'][index], bboxes['labels'][index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvQqJwTWQggH"
      },
      "source": [
        "#Inference with torchscript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynEakavUUVV8"
      },
      "source": [
        "https://pytorch.org/docs/stable/jit.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLhfUkblQjvx"
      },
      "outputs": [],
      "source": [
        "# README https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html\n",
        "# By specifying decoding option with ftp16 false ,it will fix this error\n",
        "# options = whisper.DecodingOptions(fp16 = False)\n",
        "# Half is not supported by CPU, only CUDA. https://stackoverflow.com/a/75144903\n",
        "\n",
        "class CarPlatesDetector(nn.Module):\n",
        "    def __init__(self, model: nn.Module, classes: list, size: tuple, nms_thres: float, nms_iou_thres, fp16: bool):\n",
        "        super(CarPlatesDetector, self).__init__()\n",
        "        ## YOUR CODE HERE\n",
        "        self.model = torch.jit.trace(model.float(), torch.unsqueeze(torch.rand(size).half(), 0).float()) # self.model = torch.jit.trace(model, torch.unsqueeze(torch.rand(size), 0))\n",
        "        self.size = size\n",
        "        self.classes = classes\n",
        "        self.nms_thres = nms_thres\n",
        "        self.nms_iou_thres = nms_iou_thres\n",
        "        self.fp16 = fp16\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## YOUR CODE HERE\n",
        "        return self.model.forward(x).half() # return self.model.forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlui0v4sTJCa"
      },
      "outputs": [],
      "source": [
        "state = torch.load(\n",
        "    '/content/drive/MyDrive/course_to_middle_old/weights/detector_checkpoint.ckpt',\n",
        "    map_location='cpu')\n",
        "state = state['state_dict']\n",
        "model = PLModel(RetinaRehead())\n",
        "model.load_state_dict(state)\n",
        "\n",
        "## YOUR CODE HERE\n",
        "model = model.model.eval().half() # model = model.model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEvKzKM_TR_2"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "wrapped_model = CarPlatesDetector(\n",
        "    model=model,\n",
        "    size=(3, 512, 736),\n",
        "    classes=['car', 'plate'],\n",
        "    nms_thres=0.2,\n",
        "    nms_iou_thres=0.2,\n",
        "    fp16=True # fp16=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G9jvTGbTnET"
      },
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(wrapped_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kvk7ZKaT5pf"
      },
      "outputs": [],
      "source": [
        "torch.jit.save(scripted_model, '/content/drive/MyDrive/course_to_middle_old/weights/detector_scripted.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr1DvC9qV4yp"
      },
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.load('/content/drive/MyDrive/course_to_middle_old/weights/detector_scripted.pt')\n",
        "\n",
        "## YOUR CODE HERE\n",
        "scripted_model = scripted_model.eval().half().to(device) # scripted_model = scripted_model.eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3CVd6mTQyNv"
      },
      "outputs": [],
      "source": [
        "_ = scripted_model.forward(t_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaRzpPyHWCI4"
      },
      "outputs": [],
      "source": [
        "times_for_inf_torch_script = []\n",
        "\n",
        "for i in range(100):\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  t0 = time.time()\n",
        "\n",
        "  ## YOUR CODE HERE\n",
        "  res = scripted_model.forward(t_img) # res = scripted_model.forward(t_img).half()\n",
        "\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  times_for_inf_torch_script.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for inference torch script {np.mean(np.array(times_for_inf_torch_script))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G1zVNIdQbiW"
      },
      "outputs": [],
      "source": [
        "nms_thres, iou_threshold = scripted_model.nms_thres, scripted_model.nms_iou_thres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL-zbR4KBy13"
      },
      "outputs": [],
      "source": [
        "clone_res = res.clone().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laeZEGNhWO6s"
      },
      "outputs": [],
      "source": [
        "times_for_postproc = []\n",
        "\n",
        "for i in range(100):\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  t0 = time.time()\n",
        "\n",
        "  ## YOUR CODE HERE\n",
        "  clone_res_cpu = clone_res.cpu() # clone_res_cpu = clone_res.cpu()\n",
        "  ## YOUR CODE HERE\n",
        "  clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :].float()).half() # clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :])\n",
        "  ## YOUR CODE HERE\n",
        "  bboxes = decode_result(clone_res_cpu[0].float(), threshold=nms_thres, iou_threshold=iou_threshold) # bboxes = decode_result(clone_res_cpu[0], threshold=nms_thres, iou_threshold=iou_threshold)\n",
        "\n",
        "  torch.cuda.synchronize(device=device)\n",
        "  times_for_postproc.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for postpocessing torchscript {np.mean(np.array(times_for_postproc))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-YVMeEpCOh3"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n",
        "for index in range(len(bboxes['boxes'])):\n",
        "    draw_box(bboxes['boxes'][index], bboxes['labels'][index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FZN1ui7Cd0M"
      },
      "source": [
        "#Convert to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auV0CXUlDMym"
      },
      "outputs": [],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqWTz1yKCfza"
      },
      "outputs": [],
      "source": [
        "import torch.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3GNLzTICtsT"
      },
      "outputs": [],
      "source": [
        "dummy_input=torch.randn(1, 3, 512, 736).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v0Ga-OZYE2_"
      },
      "outputs": [],
      "source": [
        "model = model.eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvXn6zpqCz0e"
      },
      "outputs": [],
      "source": [
        "torch.onnx.export(model, dummy_input, \"/content/drive/MyDrive/course_to_middle_old/weights/detector.onnx\", verbose=False) # , opset_version=12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KesDDGekDEJu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoqDs4i3xQfM"
      },
      "source": [
        "#Inference cv2 DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMACvoCn9j8k"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmTGEn5pw6r-"
      },
      "source": [
        "Инференс на cpu: <br>\n",
        "https://github.com/openvinotoolkit/openvino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEklZpK28ZG3"
      },
      "outputs": [],
      "source": [
        "model_cv = cv2.dnn.readNetFromONNX(\"/content/drive/MyDrive/course_to_middle_old/weights/detector.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLUYegEw8ZJ9"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread('/content/drive/MyDrive/course_to_middle_old/test_images_videos/photo1681218949.jpeg') # frame = cv2.imread('/content/drive/MyDrive/course_to_middle_old/test_images_videos/photo1681218949.jpeg')\n",
        "frame_rs = cv2.resize(frame, (736, 512))\n",
        "frame_rs = ((frame_rs/255) - 0.5) * 4\n",
        "frame_rs = np.expand_dims(frame_rs.transpose(2, 0, 1), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C13N8pYAAwho"
      },
      "outputs": [],
      "source": [
        "model_cv.setInput(frame_rs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EueRXjrfAwsA"
      },
      "outputs": [],
      "source": [
        "outputs = model_cv.forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvq4TyZQBEAN"
      },
      "outputs": [],
      "source": [
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDjtKCP-BKmv"
      },
      "outputs": [],
      "source": [
        "clone_res_cpu = torch.from_numpy(outputs)\n",
        "clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(clone_res_cpu[:, [0, 1, 2, 5, 6, 7], :, :])\n",
        "bboxes = decode_result(clone_res_cpu[0], threshold=0.2, iou_threshold=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIBHmiIoBK0D"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n",
        "for index in range(len(bboxes['boxes'])):\n",
        "    draw_box(bboxes['boxes'][index], bboxes['labels'][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-Fi0o8oBK2u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrZKqKEQDwSC"
      },
      "source": [
        "Convert ONNX to TensorRT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u29WRw0ZE_NL"
      },
      "source": [
        "https://developer.nvidia.com/tensorrt <br>\n",
        "https://github.com/NVIDIA/TensorRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNXmzYXkD1jT"
      },
      "outputs": [],
      "source": [
        "!pip install nvidia-tensorrt pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f820971"
      },
      "outputs": [],
      "source": [
        "# ! /usr/src/tensorrt/bin/trtexec --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba175f1e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ! /usr/src/tensorrt/bin/trtexec --onnx=/mnt/jupyter/weights/yolov5l_640_lp_new.onnx --fp16 --saveEngine=/mnt/jupyter/weights/yolov5l_640_lp_new_trt.engine "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYUc4wTSD2IT"
      },
      "outputs": [],
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqfO8WCpb7Ly"
      },
      "outputs": [],
      "source": [
        "logger = trt.Logger(trt.Logger.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJahHtW_b4z0"
      },
      "outputs": [],
      "source": [
        "builder = trt.Builder(logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4vRyI_lb42d"
      },
      "outputs": [],
      "source": [
        "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bozBd4tlb45L"
      },
      "outputs": [],
      "source": [
        "parser = trt.OnnxParser(network, logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nKm138Yb48J"
      },
      "outputs": [],
      "source": [
        "success = parser.parse_from_file('/content/drive/MyDrive/course_to_middle_old/weights/detector.onnx')\n",
        "for idx in range(parser.num_errors):\n",
        "    print(parser.get_error(idx))\n",
        "if not success:\n",
        "  print('error while parse ONNX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmOl4KAWY6pP"
      },
      "outputs": [],
      "source": [
        "config = builder.create_builder_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VUaoGQwY6ur"
      },
      "outputs": [],
      "source": [
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 << 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAOSYSnwdWu3"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "config.set_flag(trt.BuilderFlag.FP16) # # config.set_flag(trt.BuilderFlag.FP16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8laXBm8meUlr"
      },
      "outputs": [],
      "source": [
        "with builder.build_engine(network, config) as engine, open('/content/drive/MyDrive/course_to_middle_old/weights/detector.engine', 'wb') as t:\n",
        "    t.write(engine.serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUr7H4qfeXdz"
      },
      "source": [
        "# Inference with TensorRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHPyPGOJ1TTd"
      },
      "outputs": [],
      "source": [
        "logger = trt.Logger(trt.Logger.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsctBtPaeUrd"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/course_to_middle_old/weights/detector.engine', 'rb') as f:\n",
        "    serialized_engine = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRrcOmNHCuK1"
      },
      "outputs": [],
      "source": [
        "runtime = trt.Runtime(logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8ocQSukCwHv"
      },
      "outputs": [],
      "source": [
        "engine = runtime.deserialize_cuda_engine(serialized_engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2yT5YWAf1r_"
      },
      "outputs": [],
      "source": [
        "model_context = engine.create_execution_context()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCvmlVD5gUCV"
      },
      "outputs": [],
      "source": [
        "model_input_name = model_context.engine.get_tensor_name(0)\n",
        "model_input_shape = model_context.engine.get_tensor_shape(model_input_name)\n",
        "model_output_name = model_context.engine.get_tensor_name(1)\n",
        "model_output_shape = model_context.engine.get_tensor_shape(model_output_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPSowx4Zgjem"
      },
      "outputs": [],
      "source": [
        "print(model_input_name, model_input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9916c9Cdg-yF"
      },
      "outputs": [],
      "source": [
        "print(model_output_name, model_output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3mNtY2Cj6T3"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread('/content/drive/MyDrive/course_to_middle_old/test_images_videos/photo1681218949.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGaf-0UfnYJF"
      },
      "outputs": [],
      "source": [
        "class HostDeviceMem(object):\n",
        "    def __init__(self, host_mem, device_mem):\n",
        "        self.host = host_mem\n",
        "        self.device = device_mem\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zq3yqb0nQgW"
      },
      "outputs": [],
      "source": [
        "def allocate_buffers(engine):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    bindings = []\n",
        "    stream = cuda.Stream()\n",
        "    out_shapes = []\n",
        "    input_shapes = []\n",
        "    out_names = []\n",
        "    max_batch_size = engine.get_profile_shape(0, 0)[2][0]\n",
        "    for binding in engine:\n",
        "        binding_shape = engine.get_binding_shape(binding)\n",
        "        #Fix -1 dimension for proper memory allocation for batch_size > 1\n",
        "        if binding_shape[0] == -1:\n",
        "            binding_shape = (1,) + binding_shape[1:]\n",
        "        size = trt.volume(binding_shape) * max_batch_size\n",
        "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
        "        # Allocate host and device buffers\n",
        "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
        "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
        "        # Append the device buffer to device bindings.\n",
        "        bindings.append(int(device_mem))\n",
        "        # Append to the appropriate list.\n",
        "        if engine.binding_is_input(binding):\n",
        "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "            input_shapes.append(engine.get_binding_shape(binding))\n",
        "        else:\n",
        "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "            #Collect original output shapes and names from engine\n",
        "            out_shapes.append(engine.get_binding_shape(binding))\n",
        "            out_names.append(binding)\n",
        "    return inputs, outputs, bindings, stream, input_shapes, out_shapes, out_names, max_batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B90cHJLtnRQ7"
      },
      "outputs": [],
      "source": [
        "inputs, outputs, bindings, stream, input_shapes, out_shapes, out_names, max_batch_size = allocate_buffers(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKsRS4rPnRTY"
      },
      "outputs": [],
      "source": [
        "model_context.active_optimization_profile = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psTcY1zmnRW2"
      },
      "outputs": [],
      "source": [
        "def do_inference(context, bindings, inputs, outputs, stream):\n",
        "    # Transfer input data to the GPU.\n",
        "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
        "    # Run inference.\n",
        "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
        "    # Transfer predictions back from the GPU.\n",
        "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
        "    # Synchronize the stream\n",
        "    stream.synchronize()\n",
        "    # Return only the host outputs.\n",
        "    return [out.host for out in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpIsSTS1yyOs"
      },
      "outputs": [],
      "source": [
        "times_for_preprocessing_trt = []\n",
        "for i in range(100):\n",
        "  t0 = time.time()\n",
        "  frame_rs = cv2.resize(frame, (736, 512))\n",
        "  frame_rs = ((frame_rs/255) - 0.5) * 4\n",
        "  frame_rs = np.expand_dims(frame_rs.transpose(2, 0, 1), axis=0)\n",
        "  frame_rs = np.ascontiguousarray(frame_rs)\n",
        "\n",
        "  batch_size = frame_rs.shape[0]\n",
        "  allocate_place = np.prod(frame_rs.shape)\n",
        "  inputs[0].host[:allocate_place] = frame_rs.flatten(order='C').astype(np.float32)\n",
        "  model_context.set_binding_shape(0, frame_rs.shape)\n",
        "\n",
        "  times_for_preprocessing_trt.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for preprocessing for TensorRT: {np.mean(np.array(times_for_preprocessing_trt))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRlEcZPDnRax"
      },
      "outputs": [],
      "source": [
        "times_for_inf_trt = []\n",
        "for i in range(100):\n",
        "  t0 = time.time()\n",
        "  batch_size = frame_rs.shape[0]\n",
        "  allocate_place = np.prod(frame_rs.shape)\n",
        "  inputs[0].host[:allocate_place] = frame_rs.flatten(order='C').astype(np.float32)\n",
        "  model_context.set_binding_shape(0, frame_rs.shape)\n",
        "  trt_outputs = do_inference(\n",
        "      model_context, \n",
        "      bindings=bindings,\n",
        "      inputs=inputs, \n",
        "      outputs=outputs, \n",
        "      stream=stream\n",
        "  )\n",
        "\n",
        "  times_for_inf_trt.append(time.time() - t0)\n",
        "\n",
        "print(f'mean time for inference in TensorRT: {np.mean(np.array(times_for_inf_trt))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eoy0VSZTnQjE"
      },
      "outputs": [],
      "source": [
        "out = trt_outputs[0].reshape((1, 10, 64, 92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBiLgrhppUYl"
      },
      "outputs": [],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Y0y0vypXAl"
      },
      "outputs": [],
      "source": [
        "res = torch.from_numpy(out.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asArF6z-nQpW"
      },
      "outputs": [],
      "source": [
        "res[:, [0, 1, 2, 5, 6, 7], :, :] = torch.sigmoid(res[:, [0, 1, 2, 5, 6, 7], :, :])\n",
        "bboxes = decode_result(res[0], threshold=0.2, iou_threshold=0.2)\n",
        "\n",
        "plt.imshow(img)\n",
        "for index in range(len(bboxes['boxes'])):\n",
        "    draw_box(bboxes['boxes'][index], bboxes['labels'][index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lus03LIj6xF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY_pshkZ6xHT"
      },
      "source": [
        "#Работа с видео. Захват видео с cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDrvpVQN7S08"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwVtEmbW7U12"
      },
      "outputs": [],
      "source": [
        "print(cv2.getBuildInformation())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAyXCKeK63HK"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('/content/drive/MyDrive/course_to_middle_old/test_images_videos/driving_out_30sec.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfc7xCNh7qku"
      },
      "outputs": [],
      "source": [
        "times_to_grab_images = []\n",
        "while cap.isOpened():\n",
        "  t0 = time.time()\n",
        "  ret, image_np = cap.read()\n",
        "  times_to_grab_images.append(time.time() - t0)\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "  # else:\n",
        "  #   print(image_np.shape)\n",
        "\n",
        "print(f'mean time for grab image: {np.mean(np.array(times_to_grab_images))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNf55HM87u9H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-vfgRsMBNr2"
      },
      "source": [
        "# GStreamer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fIfFfgZUbuK"
      },
      "source": [
        "https://gstreamer.freedesktop.org/documentation/tutorials/index.html?gi-language=c <br>\n",
        "https://docs.gstreamer.com/ <br>\n",
        "https://gist.github.com/hum4n0id/cda96fb07a34300cdb2c0e314c14df0a <br>\n",
        "https://docs.nvidia.com/jetson/archives/r35.2.1/DeveloperGuide/text/SD/Multimedia/AcceleratedGstreamer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBXGxGQZHQlA"
      },
      "outputs": [],
      "source": [
        "# README https://github.com/pyannote/pyannote-audio/issues/1269\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K80LVnkrBL5I"
      },
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48xrCZHh8HI0"
      },
      "source": [
        "*Тут нужно перезагрузить среду*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJcOwzceBbWJ"
      },
      "outputs": [],
      "source": [
        "!apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoMrgyqJBbY2"
      },
      "outputs": [],
      "source": [
        "!apt-get install gstreamer1.0-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSoyw-7kEsim"
      },
      "outputs": [],
      "source": [
        "# %cd /content\n",
        "# !git clone https://github.com/opencv/opencv\n",
        "# !git clone https://github.com/opencv/opencv_contrib\n",
        "# !mkdir /content/build\n",
        "# %cd /content/build\n",
        "# !cmake -DOPENCV_EXTRA_MODULES_PATH=/content/opencv_contrib/modules  -DWITH_GSTREAMER=ON -DBUILD_SHARED_LIBS=OFF  -DBUILD_TESTS=OFF  -DBUILD_PERF_TESTS=OFF -DBUILD_EXAMPLES=OFF -DWITH_OPENEXR=OFF -DWITH_CUDA=ON -DWITH_CUBLAS=ON -DWITH_CUDNN=ON -DOPENCV_DNN_CUDA=ON /content/opencv\n",
        "# !make -j8 install\n",
        "# %cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyguEjlmTtyn"
      },
      "outputs": [],
      "source": [
        "# !ls /content/build/lib/python3/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt2rngNyGZDj"
      },
      "outputs": [],
      "source": [
        "# !cp /content/build/lib/python3/cv2.cpython-39-x86_64-linux-gnu.so ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtlJyv03WO-l"
      },
      "outputs": [],
      "source": [
        "# !cp ./cv2.cpython-39-x86_64-linux-gnu.so /content/drive/MyDrive/course_to_middle_old/cv2_lib/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyF9IwhEctaT"
      },
      "outputs": [],
      "source": [
        "# !ls /content/drive/MyDrive/course_to_middle/cv2_lib/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN1cubIqdgSC"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/course_to_middle/cv2_lib/cv2.cpython-39-x86_64-linux-gnu.so ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaZCzbGPc683"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiMoNhOcWH1z"
      },
      "outputs": [],
      "source": [
        "print(cv2.getBuildInformation())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmEPr-LQJqJW"
      },
      "outputs": [],
      "source": [
        "# !gst-launch-1.0 uridecodebin uri=file:///content/drive/MyDrive/course_to_middle_old/test_images_videos/driving_out_30sec.mp4  ! videoconvert ! video/x-raw, format=BGRx, width=1280, height=720 ! videoconvert ! video/x-raw, format=BGR ! fakesink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOo9n1ajNzUW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DaEnQ9R07DJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(\n",
        "    f\"uridecodebin uri=file:///content/drive/MyDrive/course_to_middle_old/test_images_videos/driving_out_30sec.mp4  ! videoconvert ! video/x-raw, format=BGRx, width=1280, height=720 ! videoconvert ! video/x-raw, format=BGR ! appsink sync=False\", \n",
        "    cv2.CAP_GSTREAMER,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIRplhZAWLXr"
      },
      "outputs": [],
      "source": [
        "times_to_grab_images_with_gst = []\n",
        "while cap.isOpened():\n",
        "  t0 = time.time()\n",
        "  ret, image_np = cap.read()\n",
        "  times_to_grab_images_with_gst.append(time.time() - t0)\n",
        "  if not ret:\n",
        "    break\n",
        "  # else:\n",
        "  #   print(image_np.shape)\n",
        "\n",
        "print(f'mean time for grab images with GStreamer: {np.mean(np.array(times_to_grab_images_with_gst))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jcoi22uYQsm"
      },
      "source": [
        "# Bonus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs0jVZitPbyV"
      },
      "outputs": [],
      "source": [
        "# README https://discuss.pytorch.org/t/converting-to-onnx-raises-cuda-out-of-memory-error/111589/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7N4GIKpYT_4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Union, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fOuUB4pVNQh"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFKna8l5ZAkE"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/course_to_middle_old/weights/lpr_epoch_42_ts.pth'\n",
        "IMG_HEIGHT, IMG_WIDTH = 224, 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eR8ah3rZOIQ"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "model = torch.jit.load(checkpoint_path, map_location='cuda').eval().half() # model = torch.jit.load(checkpoint_path, map_location='cuda').eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOh2mzLUZW53"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "warm_up_sample = torch.rand(3, IMG_HEIGHT, IMG_WIDTH).unsqueeze(0).half().to(device) # warm_up_sample = torch.rand(3, IMG_HEIGHT, IMG_WIDTH).unsqueeze(0).to(device)\n",
        "print(warm_up_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMzyWOGfZbpI"
      },
      "outputs": [],
      "source": [
        "# README https://stackoverflow.com/a/65442993\n",
        "# Reducing num_workers worked for me :D # torch.set_num_threads(1)\n",
        "# The error RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR is notoriously difficult to debug, but surprisingly often it's an out of memory problem.\n",
        "# torch.set_num_threads(1)\n",
        "# model = torch.onnx.export(\n",
        "#     model,                                    \n",
        "#     warm_up_sample,                           \n",
        "#     \"/content/drive/MyDrive/course_to_middle_old/weights/lpr_epoch_42_ts.onnx\",         \n",
        "#     opset_version=12,               \n",
        "#     verbose=False,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcs8IAkrZl_4"
      },
      "outputs": [],
      "source": [
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "success = parser.parse_from_file('/content/drive/MyDrive/course_to_middle_old/weights/lpr_epoch_42_ts.onnx')\n",
        "for idx in range(parser.num_errors):\n",
        "    print(parser.get_error(idx))\n",
        "if not success:\n",
        "  print('error while parse ONNX')\n",
        "\n",
        "config = builder.create_builder_config()\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 << 30)\n",
        "\n",
        "with builder.build_engine(network, config) as engine, open('/content/drive/MyDrive/course_to_middle_old/weights/lpr_epoch_42_ts.engine', 'wb') as t:\n",
        "    t.write(engine.serialize())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_7gJTLhbVoF"
      },
      "outputs": [],
      "source": [
        "logger = trt.Logger(trt.Logger.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b39_khSjbVoG"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/course_to_middle_old/weights/lpr_epoch_42_ts.engine', 'rb') as f:\n",
        "    serialized_engine = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgLmSMRQbVoG"
      },
      "outputs": [],
      "source": [
        "runtime = trt.Runtime(logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XFm7Fb-bVoG"
      },
      "outputs": [],
      "source": [
        "engine = runtime.deserialize_cuda_engine(serialized_engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS4MnwQxbVoG"
      },
      "outputs": [],
      "source": [
        "model_context = engine.create_execution_context()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcZy5HrnbVoG"
      },
      "outputs": [],
      "source": [
        "model_input_name = model_context.engine.get_tensor_name(0)\n",
        "model_input_shape = model_context.engine.get_tensor_shape(model_input_name)\n",
        "model_output_name = model_context.engine.get_tensor_name(1)\n",
        "model_output_shape = model_context.engine.get_tensor_shape(model_output_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g7w_bNebVoG"
      },
      "outputs": [],
      "source": [
        "print(model_input_name, model_input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lurLdxYvbVoH"
      },
      "outputs": [],
      "source": [
        "print(model_output_name, model_output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLO802CibID_"
      },
      "outputs": [],
      "source": [
        "class HostDeviceMem(object):\n",
        "    def __init__(self, host_mem, device_mem):\n",
        "        self.host = host_mem\n",
        "        self.device = device_mem\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxr7YzVJbIEA"
      },
      "outputs": [],
      "source": [
        "def allocate_buffers(engine):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    bindings = []\n",
        "    stream = cuda.Stream()\n",
        "    out_shapes = []\n",
        "    input_shapes = []\n",
        "    out_names = []\n",
        "    max_batch_size = engine.get_profile_shape(0, 0)[2][0]\n",
        "    for binding in engine:\n",
        "        binding_shape = engine.get_binding_shape(binding)\n",
        "        #Fix -1 dimension for proper memory allocation for batch_size > 1\n",
        "        if binding_shape[0] == -1:\n",
        "            binding_shape = (1,) + binding_shape[1:]\n",
        "        size = trt.volume(binding_shape) * max_batch_size\n",
        "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
        "        # Allocate host and device buffers\n",
        "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
        "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
        "        # Append the device buffer to device bindings.\n",
        "        bindings.append(int(device_mem))\n",
        "        # Append to the appropriate list.\n",
        "        if engine.binding_is_input(binding):\n",
        "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "            input_shapes.append(engine.get_binding_shape(binding))\n",
        "        else:\n",
        "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "            #Collect original output shapes and names from engine\n",
        "            out_shapes.append(engine.get_binding_shape(binding))\n",
        "            out_names.append(binding)\n",
        "    return inputs, outputs, bindings, stream, input_shapes, out_shapes, out_names, max_batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSPjm4WlbIEA"
      },
      "outputs": [],
      "source": [
        "inputs, outputs, bindings, stream, input_shapes, out_shapes, out_names, max_batch_size = allocate_buffers(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlVGq5tFbIEA"
      },
      "outputs": [],
      "source": [
        "model_context.active_optimization_profile = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3WThoLzbIEB"
      },
      "outputs": [],
      "source": [
        "def do_inference(context, bindings, inputs, outputs, stream):\n",
        "    # Transfer input data to the GPU.\n",
        "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
        "    # Run inference.\n",
        "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
        "    # Transfer predictions back from the GPU.\n",
        "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
        "    # Synchronize the stream\n",
        "    stream.synchronize()\n",
        "    # Return only the host outputs.\n",
        "    return [out.host for out in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BKn4vsWbz5d"
      },
      "outputs": [],
      "source": [
        "frame = cv2.imread('/content/drive/MyDrive/course_to_middle_old/test_images_videos/plate.png')\n",
        "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vp7TX4tWoeN"
      },
      "outputs": [],
      "source": [
        "plt.imshow(frame)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0AuhuayXxKN"
      },
      "outputs": [],
      "source": [
        "def resize_and_pad(image: np.ndarray, shape: Tuple[int]) -> np.ndarray:\n",
        "    '''\n",
        "    Resize image maintaining aspect ration and add pads to desired shape.\n",
        "    Inputs:\n",
        "    image: np.ndarray - target image\n",
        "    shape: Tuple[int] - target shape (x,y)\n",
        "    '''\n",
        "\n",
        "    t_h, t_w = shape  # change x and y\n",
        "    zeros = np.zeros((t_h, t_w, 3)).astype(np.uint8)\n",
        "    h, w, _ = image.shape\n",
        "    if w > h:\n",
        "        resized = cv2.resize(image.copy(), (t_w, int(t_h * (h / w))))\n",
        "        y = (zeros.shape[0] - resized.shape[0]) // 2\n",
        "        zeros[y:y + resized.shape[0], ...] = resized\n",
        "    elif w < h:\n",
        "        resized = cv2.resize(image.copy(), (int(t_w * (w / h)), t_h))\n",
        "        x = (zeros.shape[1] - resized.shape[1]) // 2\n",
        "        zeros[:, x:x + resized.shape[1], ...] = resized\n",
        "    else:\n",
        "        resized = cv2.resize(image.copy(), (t_w, t_h))\n",
        "        zeros = resized\n",
        "\n",
        "    return zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRlUKA0Ab--D"
      },
      "outputs": [],
      "source": [
        "frame_rs = resize_and_pad(frame, (224, 224))\n",
        "frame_rs = frame_rs.transpose((2, 0, 1))\n",
        "frame_rs = frame_rs / 255\n",
        "frame_rs = np.expand_dims(frame_rs, axis=0)\n",
        "frame_rs = np.ascontiguousarray(frame_rs)\n",
        "\n",
        "# batch_size = frame_rs.shape[0]\n",
        "# allocate_place = np.prod(frame_rs.shape)\n",
        "# inputs[0].host[:allocate_place] = frame_rs.flatten(order='C').astype(np.float32)\n",
        "# model_context.set_binding_shape(0, frame_rs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN5OuhmDb--E"
      },
      "outputs": [],
      "source": [
        "batch_size = frame_rs.shape[0]\n",
        "allocate_place = np.prod(frame_rs.shape)\n",
        "inputs[0].host[:allocate_place] = frame_rs.flatten(order='C').astype(np.float32)\n",
        "model_context.set_binding_shape(0, frame_rs.shape)\n",
        "trt_outputs = do_inference(\n",
        "    model_context, \n",
        "    bindings=bindings,\n",
        "    inputs=inputs, \n",
        "    outputs=outputs, \n",
        "    stream=stream\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AODYTP0Z53s"
      },
      "outputs": [],
      "source": [
        "trt_outputs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLyo5XBRaTtH"
      },
      "outputs": [],
      "source": [
        "trt_outputs = trt_outputs[0].reshape((1, 57, 23))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3g89rgScWWf"
      },
      "outputs": [],
      "source": [
        "alphabet = '0123456789ABCEHKMOPTXY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfmy2WzCgbki"
      },
      "outputs": [],
      "source": [
        "def topk(array, k, axis=-1, sorted=True):\n",
        "    partitioned_ind = (\n",
        "        np.argpartition(array, -k, axis=axis)\n",
        "        .take(indices=range(-k, 0), axis=axis)\n",
        "    )\n",
        "    partitioned_scores = np.take_along_axis(array, partitioned_ind, axis=axis)\n",
        "    \n",
        "    if sorted:\n",
        "        sorted_trunc_ind = np.flip(\n",
        "            np.argsort(partitioned_scores, axis=axis), axis=axis\n",
        "        )\n",
        "        \n",
        "        ind = np.take_along_axis(partitioned_ind, sorted_trunc_ind, axis=axis)\n",
        "        scores = np.take_along_axis(partitioned_scores, sorted_trunc_ind, axis=axis)\n",
        "    else:\n",
        "        ind = partitioned_ind\n",
        "        scores = partitioned_scores\n",
        "    \n",
        "    return scores, ind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU8IYWUtb5Gm"
      },
      "outputs": [],
      "source": [
        "confidences, symbols = [i.flatten() for i in topk(trt_outputs[0], 1, axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrXruH-thb-W"
      },
      "outputs": [],
      "source": [
        "symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QMI2DqJcSzu"
      },
      "outputs": [],
      "source": [
        "blank = len(alphabet)\n",
        "label, conf_list, buf = '', list(), blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhZjCQwtcS2X"
      },
      "outputs": [],
      "source": [
        "for i in range(symbols.shape[0]):\n",
        "    if symbols[i] == blank or symbols[i] == buf:\n",
        "        buf = symbols[i]\n",
        "        continue\n",
        "\n",
        "    buf = symbols[i]\n",
        "    label += alphabet[buf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EGJVL7XhHQK"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fycVbO8khYPY"
      },
      "outputs": [],
      "source": [
        "plt.imshow(frame)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kan_sCwE-cdk"
      },
      "source": [
        "# Application"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!(rm -rf /content/drive/MyDrive/course_to_middle && git clone https://github.com/innovator1984/course_to_middle /content/drive/MyDrive/course_to_middle)"
      ],
      "metadata": {
        "id": "oGsAyYWuDrag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!(cd /content/drive/MyDrive/course_to_middle && git checkout feature/course_to_middle)"
      ],
      "metadata": {
        "id": "MEmGGowtOifa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPOkBhYyFsoh"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Edu/5.\\ Inference/cv2_lib/cv2.cpython-39-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python==4.6.0.66"
      ],
      "metadata": {
        "id": "malB5SRiIQ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/course_to_middle/weights/ && cp -r /content/drive/MyDrive/Edu/5.\\ Inference/weights/ /content/drive/MyDrive/course_to_middle/weights/"
      ],
      "metadata": {
        "id": "xZT-JJghJ7Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!(rm -rf /content/drive/MyDrive/course_to_middle/videos/ && cp -r /content/drive/MyDrive/Edu/5.\\ Inference/test_images_videos/ /content/drive/MyDrive/course_to_middle/videos/ )"
      ],
      "metadata": {
        "id": "HrMTgvZmPkyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!(ls /content/drive/MyDrive/course_to_middle/videos/)"
      ],
      "metadata": {
        "id": "JZdY2YgTTY-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IvHGRF1-tW5"
      },
      "outputs": [],
      "source": [
        "!python3 /content/drive/MyDrive/course_to_middle/pursuit_detection/pursuit_detection.py --input-video /content/drive/MyDrive/course_to_middle/videos/driving_out_30sec.mp4 --output-video /content/drive/MyDrive/course_to_middle/videos/driving_out_30sec_result.mp4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}